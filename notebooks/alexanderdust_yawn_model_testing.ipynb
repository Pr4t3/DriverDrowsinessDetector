{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebdc5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1233 images belonging to 2 classes.\n",
      "Found 1233 images belonging to 2 classes.\n",
      "38 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 16:38:50.284274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/alessandrorinaldi/.pyenv/versions/3.8.12/envs/DriverDrowsinessDetector/lib/python3.8/site-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-03-02 16:38:50.831699: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "38/38 [==============================] - 18s 212ms/step - loss: 0.6837 - recall: 0.4864 - val_loss: 0.5882 - val_recall: 0.6179\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 7s 185ms/step - loss: 0.5763 - recall: 0.6326 - val_loss: 0.5124 - val_recall: 0.6565\n",
      "Epoch 3/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.5286 - recall: 0.6694 - val_loss: 0.4722 - val_recall: 0.6857\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 7s 179ms/step - loss: 0.4894 - recall: 0.6956 - val_loss: 0.4159 - val_recall: 0.7091\n",
      "Epoch 5/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.4715 - recall: 0.7161 - val_loss: 0.3439 - val_recall: 0.7269\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.3857 - recall: 0.7348 - val_loss: 0.2540 - val_recall: 0.7489\n",
      "Epoch 7/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.3151 - recall: 0.7586 - val_loss: 0.1731 - val_recall: 0.7722\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.2909 - recall: 0.7801 - val_loss: 0.1448 - val_recall: 0.7909\n",
      "Epoch 9/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.2066 - recall: 0.7977 - val_loss: 0.0921 - val_recall: 0.8083\n",
      "Epoch 10/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.1295 - recall: 0.8150 - val_loss: 0.0855 - val_recall: 0.8245\n",
      "Epoch 11/15\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 0.1399 - recall: 0.8298 - val_loss: 0.0498 - val_recall: 0.8379\n",
      "Epoch 12/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.0927 - recall: 0.8427 - val_loss: 0.0468 - val_recall: 0.8495\n",
      "Epoch 13/15\n",
      "38/38 [==============================] - 7s 192ms/step - loss: 0.1023 - recall: 0.8534 - val_loss: 0.0259 - val_recall: 0.8597\n",
      "Epoch 14/15\n",
      "38/38 [==============================] - 7s 183ms/step - loss: 0.0928 - recall: 0.8633 - val_loss: 0.0250 - val_recall: 0.8688\n",
      "Epoch 15/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.0476 - recall: 0.8722 - val_loss: 0.0181 - val_recall: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1bf3910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random,shutil\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
    "\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)\n",
    "\n",
    "BS= 32\n",
    "TS=(24,24)\n",
    "train_batch= generator('../raw_data/yawn/train_yawn',shuffle=True, batch_size=BS,target_size=TS)\n",
    "valid_batch= generator('../raw_data/yawn/train_yawn',shuffle=True, batch_size=BS,target_size=TS)\n",
    "SPE= len(train_batch.classes)//BS\n",
    "VS = len(valid_batch.classes)//BS\n",
    "print(SPE,VS)\n",
    "\n",
    "\n",
    "# img,labels= next(train_batch)\n",
    "# print(img.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "    Dropout(0.25),\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "    Flatten(),\n",
    "#fully connected to get all relevant data\n",
    "    Dense(128, activation='relu'),\n",
    "#one more dropout for convergence' sake :)\n",
    "    Dropout(0.5),\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "recall = tensorflow.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[recall])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n",
    "#model.save('models/model_yawn.h5', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b01a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "38/38 [==============================] - 8s 197ms/step - loss: 0.6815 - recall_2: 0.5061 - val_loss: 0.5664 - val_recall_2: 0.6312\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 7s 183ms/step - loss: 0.5639 - recall_2: 0.6521 - val_loss: 0.5071 - val_recall_2: 0.6762\n",
      "Epoch 3/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.5517 - recall_2: 0.6849 - val_loss: 0.4446 - val_recall_2: 0.7007\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.4623 - recall_2: 0.7108 - val_loss: 0.4257 - val_recall_2: 0.7248\n",
      "Epoch 5/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.4471 - recall_2: 0.7325 - val_loss: 0.3589 - val_recall_2: 0.7464\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 7s 179ms/step - loss: 0.4068 - recall_2: 0.7535 - val_loss: 0.2468 - val_recall_2: 0.7665\n",
      "Epoch 7/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.2898 - recall_2: 0.7746 - val_loss: 0.1880 - val_recall_2: 0.7870\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.2187 - recall_2: 0.7949 - val_loss: 0.1509 - val_recall_2: 0.8063\n",
      "Epoch 9/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.1830 - recall_2: 0.8133 - val_loss: 0.0713 - val_recall_2: 0.8236\n",
      "Epoch 10/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.1287 - recall_2: 0.8298 - val_loss: 0.0553 - val_recall_2: 0.8386\n",
      "Epoch 11/15\n",
      "38/38 [==============================] - 7s 189ms/step - loss: 0.1117 - recall_2: 0.8438 - val_loss: 0.0333 - val_recall_2: 0.8514\n",
      "Epoch 12/15\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.0790 - recall_2: 0.8561 - val_loss: 0.0243 - val_recall_2: 0.8629\n",
      "Epoch 13/15\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 0.0522 - recall_2: 0.8671 - val_loss: 0.0216 - val_recall_2: 0.8730\n",
      "Epoch 14/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.0582 - recall_2: 0.8764 - val_loss: 0.0165 - val_recall_2: 0.8815\n",
      "Epoch 15/15\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.0259 - recall_2: 0.8846 - val_loss: 0.0068 - val_recall_2: 0.8892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c453bd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid Function - recall improve by 0.01%\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "    Dropout(0.25),\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "    Flatten(),\n",
    "#fully connected to get all relevant data\n",
    "    Dense(128, activation='relu'),\n",
    "#one more dropout for convergence' sake :)\n",
    "    Dropout(0.5),\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "recall = tensorflow.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[recall])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b92d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/model_yawn.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fe908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
